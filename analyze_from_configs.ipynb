{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get config jsons from fine-tuning experiments and analyze\n",
    "\n",
    "## Ny kj√∏ring i 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys, io, shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01121625: tsa-bin 36\n",
      "01150927: tsa-intensity 21\n",
      "01150927: tsa-bin 21\n",
      "01170939: tsa-bin 42\n",
      "01170944: tsa-intensity 42\n",
      "01191518: tsa-intensity 48\n",
      "01191518: tsa-bin 50\n",
      "08161327: tsa-intensity 36\n",
      "08161531: tsa-bin 36\n",
      "08231013: tsa-intensity 6\n",
      "08231013: tsa-bin 6\n",
      "08231514: tsa-intensity 2\n",
      "08231514: tsa-bin 2\n",
      "08251110: tsa-intensity 12\n"
     ]
    }
   ],
   "source": [
    "# Get timestamps and tasks\n",
    "configs_path = Path(\"/home/egil/gits_wsl/seq-label-github/configs/fox\")\n",
    "all_jsons = [f for f in configs_path.iterdir() if f.name.endswith(\"json\")]\n",
    "all_jsons = [(f.stem.split(\"_\")[0], f.stem.split(\"_\")[1], f) for f in all_jsons]\n",
    "timestamps = sorted(list(set([j[0] for j in all_jsons])))\n",
    "for t in timestamps:\n",
    "    tasks = set([j[1] for j in all_jsons if j[0]==t])\n",
    "    for task in tasks:\n",
    "        print(f\"{t}: {task}\", len([j for j in all_jsons if j[0]==t and j[1]==task]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "name_filter = [\"0115\", \"0117\"]\n",
    "name_filter = [\"01191518_tsa-bin_NB-BERT_large_07-b\"]\n",
    "name_filter = [\"01191518_tsa-bin_NorBERT_3_base_04_b\"] # \"01170944\" # \n",
    "jsons = [f[2] for f in all_jsons if any([f[0] in n for n in name_filter])]\n",
    "jsons = [f[2] for f in all_jsons if name_filter[0] in f[2].name]\n",
    "\n",
    "name_filter = \"_\".join(name_filter)\n",
    "len(jsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"timestamp\": \"01191518\", \"num_seeds\": 1, \"task\": \"tsa-bin\", \"model_shortname\": \"NorBERT_3_base\", \"machinery\": \"fox\", \"local_dataset\": false, \"args_dict\": {\"model_name_or_path\": \"ltg/norbert3-base\", \"dataset_name\": \"ltg/norec_tsa,default\", \"seed\": 101, \"per_device_train_batch_size\": 8, \"task_name\": \"01191518_tsa-bin_NorBERT_3_base\", \"output_dir\": \"/cluster/work/projects/ec30/egilron/tsa-hf/01191518_tsa-bin_NorBERT_3_base_final\", \"overwrite_cache\": true, \"overwrite_output_dir\": true, \"do_train\": true, \"num_train_epochs\": 24, \"do_eval\": true, \"return_entity_level_metrics\": false, \"use_auth_token\": false, \"logging_strategy\": \"epoch\", \"save_strategy\": \"epoch\", \"evaluation_strategy\": \"epoch\", \"save_total_limit\": 1, \"load_best_model_at_end\": true, \"label_column_name\": \"tsa_tags\", \"disable_tqdm\": true, \"do_predict\": true, \"text_column_name\": \"tokens\", \"learning_rate\": 2e-05}, \"best_epoch\": 6, \"train_epochs_val\": [{\"eval_loss\": 0.27332165837287903, \"eval_precision\": 0.5255157437567861, \"eval_recall\": 0.5518814139110604, \"eval_f1\": 0.5383759733036707, \"eval_accuracy\": 0.9523662472014205, \"eval_runtime\": 3.0936, \"eval_samples_per_second\": 494.885, \"eval_steps_per_second\": 62.063, \"epoch\": 6.0, \"step\": 6480}, {\"eval_loss\": 0.4614608585834503, \"eval_precision\": 0.5323496027241771, \"eval_recall\": 0.5347776510832383, \"eval_f1\": 0.5335608646188852, \"eval_accuracy\": 0.95167142746854, \"eval_runtime\": 3.0924, \"eval_samples_per_second\": 495.083, \"eval_steps_per_second\": 62.087, \"epoch\": 24.0, \"step\": 25920}, {\"eval_loss\": 0.450753390789032, \"eval_precision\": 0.5261401557285873, \"eval_recall\": 0.5393386545039909, \"eval_f1\": 0.5326576576576576, \"eval_accuracy\": 0.9518258318536247, \"eval_runtime\": 3.0938, \"eval_samples_per_second\": 494.867, \"eval_steps_per_second\": 62.06, \"epoch\": 22.0, \"step\": 23760}, {\"eval_loss\": 0.4555513858795166, \"eval_precision\": 0.5183982683982684, \"eval_recall\": 0.5461801596351197, \"eval_f1\": 0.5319267073847862, \"eval_accuracy\": 0.9500501814251525, \"eval_runtime\": 3.0964, \"eval_samples_per_second\": 494.437, \"eval_steps_per_second\": 62.007, \"epoch\": 20.0, \"step\": 21600}, {\"eval_loss\": 0.418249249458313, \"eval_precision\": 0.5406360424028268, \"eval_recall\": 0.5233751425313569, \"eval_f1\": 0.5318655851680184, \"eval_accuracy\": 0.9521732417200649, \"eval_runtime\": 3.095, \"eval_samples_per_second\": 494.666, \"eval_steps_per_second\": 62.035, \"epoch\": 16.0, \"step\": 17280}, {\"eval_loss\": 0.45707055926322937, \"eval_precision\": 0.5396449704142012, \"eval_recall\": 0.5199543899657925, \"eval_f1\": 0.5296167247386759, \"eval_accuracy\": 0.9519030340461669, \"eval_runtime\": 3.0985, \"eval_samples_per_second\": 494.109, \"eval_steps_per_second\": 61.965, \"epoch\": 23.0, \"step\": 24840}, {\"eval_loss\": 0.4406270980834961, \"eval_precision\": 0.5290102389078498, \"eval_recall\": 0.5302166476624858, \"eval_f1\": 0.5296127562642369, \"eval_accuracy\": 0.951632826372269, \"eval_runtime\": 3.0892, \"eval_samples_per_second\": 495.591, \"eval_steps_per_second\": 62.151, \"epoch\": 17.0, \"step\": 18360}, {\"eval_loss\": 0.4182497262954712, \"eval_precision\": 0.5496932515337424, \"eval_recall\": 0.5108323831242874, \"eval_f1\": 0.5295508274231678, \"eval_accuracy\": 0.952520651586505, \"eval_runtime\": 3.0983, \"eval_samples_per_second\": 494.149, \"eval_steps_per_second\": 61.97, \"epoch\": 13.0, \"step\": 14040}, {\"eval_loss\": 0.45938989520072937, \"eval_precision\": 0.5454545454545454, \"eval_recall\": 0.5062713797035348, \"eval_f1\": 0.5251330573625074, \"eval_accuracy\": 0.9515170230834555, \"eval_runtime\": 3.0928, \"eval_samples_per_second\": 495.018, \"eval_steps_per_second\": 62.079, \"epoch\": 21.0, \"step\": 22680}, {\"eval_loss\": 0.4318113625049591, \"eval_precision\": 0.5243055555555556, \"eval_recall\": 0.5165336374002281, \"eval_f1\": 0.5203905801263641, \"eval_accuracy\": 0.9509380066393885, \"eval_runtime\": 3.0914, \"eval_samples_per_second\": 495.252, \"eval_steps_per_second\": 62.109, \"epoch\": 15.0, \"step\": 16200}, {\"eval_loss\": 0.46018674969673157, \"eval_precision\": 0.49583333333333335, \"eval_recall\": 0.5427594070695553, \"eval_f1\": 0.5182362547632008, \"eval_accuracy\": 0.9476955145526132, \"eval_runtime\": 3.1707, \"eval_samples_per_second\": 482.865, \"eval_steps_per_second\": 60.555, \"epoch\": 19.0, \"step\": 20520}, {\"eval_loss\": 0.17888742685317993, \"eval_precision\": 0.48, \"eval_recall\": 0.5610034207525656, \"eval_f1\": 0.5173501577287066, \"eval_accuracy\": 0.9505519956766773, \"eval_runtime\": 3.0993, \"eval_samples_per_second\": 493.984, \"eval_steps_per_second\": 61.95, \"epoch\": 3.0, \"step\": 3240}, {\"eval_loss\": 0.45653989911079407, \"eval_precision\": 0.5474358974358975, \"eval_recall\": 0.4868871151653364, \"eval_f1\": 0.5153892576946288, \"eval_accuracy\": 0.951632826372269, \"eval_runtime\": 3.0995, \"eval_samples_per_second\": 493.953, \"eval_steps_per_second\": 61.946, \"epoch\": 18.0, \"step\": 19440}, {\"eval_loss\": 0.40957316756248474, \"eval_precision\": 0.5178777393310265, \"eval_recall\": 0.5119726339794755, \"eval_f1\": 0.5149082568807339, \"eval_accuracy\": 0.9509766077356597, \"eval_runtime\": 3.0905, \"eval_samples_per_second\": 495.384, \"eval_steps_per_second\": 62.125, \"epoch\": 12.0, \"step\": 12960}, {\"eval_loss\": 0.2219218909740448, \"eval_precision\": 0.537888198757764, \"eval_recall\": 0.49372862029646525, \"eval_f1\": 0.5148632580261593, \"eval_accuracy\": 0.9523662472014205, \"eval_runtime\": 3.0963, \"eval_samples_per_second\": 494.457, \"eval_steps_per_second\": 62.009, \"epoch\": 4.0, \"step\": 4320}, {\"eval_loss\": 0.42958763241767883, \"eval_precision\": 0.5229681978798587, \"eval_recall\": 0.5062713797035348, \"eval_f1\": 0.5144843568945539, \"eval_accuracy\": 0.9522504439126072, \"eval_runtime\": 3.0932, \"eval_samples_per_second\": 494.962, \"eval_steps_per_second\": 62.072, \"epoch\": 14.0, \"step\": 15120}, {\"eval_loss\": 0.3736277222633362, \"eval_precision\": 0.49269311064718163, \"eval_recall\": 0.5381984036488028, \"eval_f1\": 0.5144414168937329, \"eval_accuracy\": 0.9490465529221029, \"eval_runtime\": 3.0994, \"eval_samples_per_second\": 493.966, \"eval_steps_per_second\": 61.947, \"epoch\": 10.0, \"step\": 10800}, {\"eval_loss\": 0.33818164467811584, \"eval_precision\": 0.5027382256297919, \"eval_recall\": 0.5233751425313569, \"eval_f1\": 0.5128491620111733, \"eval_accuracy\": 0.9504361923878638, \"eval_runtime\": 3.0982, \"eval_samples_per_second\": 494.165, \"eval_steps_per_second\": 61.972, \"epoch\": 8.0, \"step\": 8640}, {\"eval_loss\": 0.24203142523765564, \"eval_precision\": 0.4819277108433735, \"eval_recall\": 0.5473204104903079, \"eval_f1\": 0.5125467164975974, \"eval_accuracy\": 0.9491237551146453, \"eval_runtime\": 3.0967, \"eval_samples_per_second\": 494.39, \"eval_steps_per_second\": 62.001, \"epoch\": 5.0, \"step\": 5400}, {\"eval_loss\": 0.38577356934547424, \"eval_precision\": 0.5320197044334976, \"eval_recall\": 0.4925883694412771, \"eval_f1\": 0.5115452930728241, \"eval_accuracy\": 0.951941635142438, \"eval_runtime\": 3.0913, \"eval_samples_per_second\": 495.265, \"eval_steps_per_second\": 62.11, \"epoch\": 11.0, \"step\": 11880}, {\"eval_loss\": 0.3048453629016876, \"eval_precision\": 0.49413020277481323, \"eval_recall\": 0.5279361459521095, \"eval_f1\": 0.5104740904079383, \"eval_accuracy\": 0.9503975912915927, \"eval_runtime\": 3.0949, \"eval_samples_per_second\": 494.69, \"eval_steps_per_second\": 62.038, \"epoch\": 7.0, \"step\": 7560}, {\"eval_loss\": 0.35316839814186096, \"eval_precision\": 0.47469635627530365, \"eval_recall\": 0.5347776510832383, \"eval_f1\": 0.5029490616621983, \"eval_accuracy\": 0.9490465529221029, \"eval_runtime\": 3.1624, \"eval_samples_per_second\": 484.125, \"eval_steps_per_second\": 60.713, \"epoch\": 9.0, \"step\": 9720}, {\"eval_loss\": 0.17784066498279572, \"eval_precision\": 0.45234899328859063, \"eval_recall\": 0.38426453819840367, \"eval_f1\": 0.4155363748458693, \"eval_accuracy\": 0.9484675364780359, \"eval_runtime\": 3.1315, \"eval_samples_per_second\": 488.903, \"eval_steps_per_second\": 61.313, \"epoch\": 1.0, \"step\": 1080}, {\"eval_loss\": 0.17299795150756836, \"eval_precision\": 0.5184534270650264, \"eval_recall\": 0.3363740022805017, \"eval_f1\": 0.4080221300138313, \"eval_accuracy\": 0.9504361923878638, \"eval_runtime\": 3.0962, \"eval_samples_per_second\": 494.483, \"eval_steps_per_second\": 62.012, \"epoch\": 2.0, \"step\": 2160}]}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons[0].read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyover(file_l:list[Path], dest_folder:str):\n",
    "    dest_folder = Path(\"history\", dest_folder)\n",
    "    dest_folder.mkdir(exist_ok=True, parents=True)\n",
    "    for f in file_l:\n",
    "        shutil.copy(f, dest_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (24, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>config-file</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>eval_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01191518</td>\n",
       "      <td>01191518_tsa-bin_NorBERT_3_base_04_b.json</td>\n",
       "      <td>ltg/norbert3-base</td>\n",
       "      <td>ltg/norec_tsa,default</td>\n",
       "      <td>/cluster/work/projects/ec30/egilron/tsa-hf/011...</td>\n",
       "      <td>0.538376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01191518</td>\n",
       "      <td>01191518_tsa-bin_NorBERT_3_base_04_b.json</td>\n",
       "      <td>ltg/norbert3-base</td>\n",
       "      <td>ltg/norec_tsa,default</td>\n",
       "      <td>/cluster/work/projects/ec30/egilron/tsa-hf/011...</td>\n",
       "      <td>0.533561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01191518</td>\n",
       "      <td>01191518_tsa-bin_NorBERT_3_base_04_b.json</td>\n",
       "      <td>ltg/norbert3-base</td>\n",
       "      <td>ltg/norec_tsa,default</td>\n",
       "      <td>/cluster/work/projects/ec30/egilron/tsa-hf/011...</td>\n",
       "      <td>0.532658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp                                config-file model_name_or_path  \\\n",
       "0  01191518  01191518_tsa-bin_NorBERT_3_base_04_b.json  ltg/norbert3-base   \n",
       "1  01191518  01191518_tsa-bin_NorBERT_3_base_04_b.json  ltg/norbert3-base   \n",
       "2  01191518  01191518_tsa-bin_NorBERT_3_base_04_b.json  ltg/norbert3-base   \n",
       "\n",
       "            dataset_name                                         output_dir  \\\n",
       "0  ltg/norec_tsa,default  /cluster/work/projects/ec30/egilron/tsa-hf/011...   \n",
       "1  ltg/norec_tsa,default  /cluster/work/projects/ec30/egilron/tsa-hf/011...   \n",
       "2  ltg/norec_tsa,default  /cluster/work/projects/ec30/egilron/tsa-hf/011...   \n",
       "\n",
       "    eval_f1  \n",
       "0  0.538376  \n",
       "1  0.533561  \n",
       "2  0.532658  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "completed_paths, records = [], []\n",
    "root_keys = [\"timestamp\",  \"task\",  \"machinery\",  \"best_epoch\" ]\n",
    "args_keys = [ 'model_name_or_path', 'task_name', 'dataset_name', 'output_dir', 'seed' , 'per_device_train_batch_size',  'learning_rate' , 'num_train_epochs']\n",
    "epoch_keys = ['eval_loss', 'eval_precision', 'eval_recall', 'eval_f1', 'eval_accuracy','epoch', 'step' ]\n",
    "for j in jsons:\n",
    "    jdata = json.loads(j.read_text())\n",
    "    try:\n",
    "        for epoch_data in jdata[\"train_epochs_val\"]:\n",
    "            record = {k:v for k,v in jdata.items() if k in root_keys}\n",
    "            record[\"config-file\"] = j.name\n",
    "            record.update({k:v for k,v in jdata[\"args_dict\"].items() if k in args_keys})\n",
    "            record.update({k:v for k,v in epoch_data.items() if k in epoch_keys})\n",
    "            records.append(record)\n",
    "            completed_paths.append(j)\n",
    "    except:\n",
    "        print(j.name, \"Seems not to have completed training\")\n",
    "df = pd.DataFrame.from_records(records)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "xc_path = Path(\"excels\", name_filter+\"_full-report.xlsx\" )\n",
    "\n",
    "df.to_excel(xc_path, index=False)\n",
    "copyover(completed_paths, name_filter+\"_\"+configs_path.stem)\n",
    "df[df[\"model_name_or_path\"].isin([\"ltg/norbert3-base\"])].sort_values(\"eval_f1\", ascending=False)[[\"timestamp\",\"config-file\" ,\"model_name_or_path\" , \"dataset_name\",\"output_dir\",\"eval_f1\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report hyperparameters\n",
    "cols = [\"timestamp\",   \"machinery\", 'model_name_or_path', 'task_name', 'dataset_name', 'seed' , 'per_device_train_batch_size',  'learning_rate' , 'num_train_epochs']\n",
    "records = []\n",
    "for col in cols:\n",
    "    record = {col: df[col].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.at[1080,\"output_dir\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df[df[\"output_dir\"].isin(['/cluster/work/projects/ec30/egilron/tsa-hf/01191518_tsa-bin_NorBERT_3_base'])].sort_values(\"eval_f1\", ascending=False)[[\"timestamp\",\"config-file\" ,\"model_name_or_path\" , \"dataset_name\",\"output_dir\",\"eval_f1\"]].head(7).iterrows():\n",
    "    print(row.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"timestamp\",   \"machinery\", 'model_name_or_path','dataset_name', 'seed' , 'per_device_train_batch_size',  'learning_rate' , 'num_train_epochs']\n",
    "records = {}\n",
    "longest = 0\n",
    "for col in cols:\n",
    "    records[col]= df[col].unique()\n",
    "    longest = max(longest, len(records[col]))\n",
    "df_vars = pd.DataFrame(columns=cols)\n",
    "for i in range(longest):\n",
    "    for col in cols:\n",
    "        try:\n",
    "            df_vars.at[i, col] =records[col][i]\n",
    "            if col==\"learning_rate\":\n",
    "                df_vars.at[i, col] =f\"{records[col][i]}\"\n",
    "\n",
    "        except:\n",
    "            df_vars.at[i, col] =\"\"\n",
    "df_vars\n",
    "xc_path = Path(\"excels\", name_filter+\"_search-space.xlsx\" )\n",
    "df_vars.to_excel(xc_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>task</th>\n",
       "      <th>machinery</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01191518</td>\n",
       "      <td>tsa-bin</td>\n",
       "      <td>fox</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>NbAiLab/nb-bert-large</td>\n",
       "      <td>8</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>0.356878</td>\n",
       "      <td>0.562988</td>\n",
       "      <td>0.575827</td>\n",
       "      <td>0.569335</td>\n",
       "      <td>0.95584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp     task machinery  num_train_epochs  best_epoch  \\\n",
       "0  01191518  tsa-bin       fox                24           9   \n",
       "\n",
       "      model_name_or_path  per_device_train_batch_size learning_rate  \\\n",
       "0  NbAiLab/nb-bert-large                            8         2e-05   \n",
       "\n",
       "   eval_loss  eval_precision  eval_recall   eval_f1  eval_accuracy  \n",
       "0   0.356878        0.562988     0.575827  0.569335        0.95584  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best epochs only\n",
    "df_bests = df.loc[ df[\"epoch\"] ==df[\"best_epoch\"]].copy()\n",
    "df_bests[\"learning_rate\"] = df_bests[\"learning_rate\"].apply(lambda x: f\"{x:.0e}\")\n",
    "report = df_bests[['timestamp', 'task', 'machinery', 'num_train_epochs', 'best_epoch', \n",
    "       'model_name_or_path',\n",
    "       'per_device_train_batch_size',  \n",
    "      'learning_rate', 'eval_loss', 'eval_precision',\n",
    "       'eval_recall', 'eval_f1', 'eval_accuracy',  ]].sort_values(\"eval_f1\", ascending=False)\n",
    "xc_path = Path(\"excels\", name_filter+\"_best-report.xlsx\" )\n",
    "report.to_excel(xc_path, index=False)\n",
    "report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ja.json'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list({1:11}.values())[0]\n",
    "from pathlib import Path\n",
    "Path(\"ja.json\").name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
