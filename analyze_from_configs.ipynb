{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get config jsons from fine-tuning experiments and analyze\n",
    "\n",
    "## Ny kj√∏ring i 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys, io, shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03081014: elsa-intensity 30\n",
      "03091023: elsa-intensity 60\n",
      "03111215: ner2 12\n",
      "03121434: elsa-polarity 36\n"
     ]
    }
   ],
   "source": [
    "# Get timestamps and tasks\n",
    "configs_path = Path(\"/home/egil/gits_wsl/seq-label-github/configs/saga\")\n",
    "all_jsons = [f for f in configs_path.iterdir() if f.name.endswith(\"json\")]\n",
    "all_jsons = [(f.stem.split(\"_\")[0], f.stem.split(\"_\")[1], f) for f in all_jsons]\n",
    "timestamps = sorted(list(set([j[0] for j in all_jsons])))\n",
    "for t in timestamps:\n",
    "    tasks = set([j[1] for j in all_jsons if j[0]==t])\n",
    "    for task in tasks:\n",
    "        print(f\"{t}: {task}\", len([j for j in all_jsons if j[0]==t and j[1]==task]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "name_filter = [\"0115\", \"0117\"]\n",
    "name_filter = [\"01191518_tsa-bin_NB-BERT_large_07-b\"]\n",
    "name_filter = [\"03111215\"] # \"01170944\" # \n",
    "jsons = [f[2] for f in all_jsons if any([f[0] in n for n in name_filter])]\n",
    "jsons = [f[2] for f in all_jsons if name_filter[0] in f[2].name]\n",
    "\n",
    "name_filter = \"_\".join(name_filter)\n",
    "len(jsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"timestamp\": \"03111215\", \"num_seeds\": 1, \"task\": \"ner2\", \"model_shortname\": \"norbert3-large\", \"machinery\": \"saga\", \"local_dataset\": true, \"args_dict\": {\"model_name_or_path\": \"ltg/norbert3-large\", \"dataset_name\": \"data/ner_2cat\", \"seed\": 101, \"per_device_train_batch_size\": 64, \"task_name\": \"03111215_ner2_norbert3-large\", \"output_dir\": \"/cluster/work/users/egilron/finetunes/03111215_ner2_norbert3-large\", \"overwrite_cache\": true, \"overwrite_output_dir\": true, \"do_train\": true, \"num_train_epochs\": 12, \"do_eval\": true, \"return_entity_level_metrics\": false, \"use_auth_token\": false, \"logging_strategy\": \"epoch\", \"save_strategy\": \"epoch\", \"evaluation_strategy\": \"epoch\", \"save_total_limit\": 1, \"load_best_model_at_end\": true, \"label_column_name\": \"ner_labels\", \"disable_tqdm\": true, \"report_to\": null, \"do_predict\": true, \"text_column_name\": \"tokens\", \"learning_rate\": 1e-05, \"trust_remote_code\": true}, \"best_epoch\": 9, \"train_epochs_val\": [{\"eval_loss\": 0.01571115292608738, \"eval_precision\": 0.954498448810755, \"eval_recall\": 0.9710678590215676, \"eval_f1\": 0.9627118644067797, \"eval_accuracy\": 0.997737322350227, \"eval_runtime\": 15.3021, \"eval_samples_per_second\": 281.007, \"eval_steps_per_second\": 35.159, \"epoch\": 9.0, \"step\": 4203}, {\"eval_loss\": 0.0162094384431839, \"eval_precision\": 0.9573361082206036, \"eval_recall\": 0.9679116254602841, \"eval_f1\": 0.9625948208213445, \"eval_accuracy\": 0.997737322350227, \"eval_runtime\": 15.376, \"eval_samples_per_second\": 279.657, \"eval_steps_per_second\": 34.99, \"epoch\": 10.0, \"step\": 4670}, {\"eval_loss\": 0.01670410856604576, \"eval_precision\": 0.9568382735309412, \"eval_recall\": 0.9679116254602841, \"eval_f1\": 0.9623430962343096, \"eval_accuracy\": 0.997737322350227, \"eval_runtime\": 15.2918, \"eval_samples_per_second\": 281.196, \"eval_steps_per_second\": 35.182, \"epoch\": 11.0, \"step\": 5137}, {\"eval_loss\": 0.01690272055566311, \"eval_precision\": 0.9553710430721328, \"eval_recall\": 0.9684376643871646, \"eval_f1\": 0.9618599791013583, \"eval_accuracy\": 0.9977077448646091, \"eval_runtime\": 15.4639, \"eval_samples_per_second\": 278.066, \"eval_steps_per_second\": 34.791, \"epoch\": 12.0, \"step\": 5604}, {\"eval_loss\": 0.014405391179025173, \"eval_precision\": 0.9591623036649215, \"eval_recall\": 0.9637033140452393, \"eval_f1\": 0.96142744686434, \"eval_accuracy\": 0.9976781673789911, \"eval_runtime\": 15.2891, \"eval_samples_per_second\": 281.245, \"eval_steps_per_second\": 35.188, \"epoch\": 7.0, \"step\": 3269}, {\"eval_loss\": 0.012067076750099659, \"eval_precision\": 0.9557982319292772, \"eval_recall\": 0.9668595476065229, \"eval_f1\": 0.9612970711297072, \"eval_accuracy\": 0.997737322350227, \"eval_runtime\": 15.3104, \"eval_samples_per_second\": 280.855, \"eval_steps_per_second\": 35.14, \"epoch\": 5.0, \"step\": 2335}, {\"eval_loss\": 0.010502147488296032, \"eval_precision\": 0.9600840336134454, \"eval_recall\": 0.961599158337717, \"eval_f1\": 0.9608409986859396, \"eval_accuracy\": 0.9976190124077552, \"eval_runtime\": 15.3693, \"eval_samples_per_second\": 279.778, \"eval_steps_per_second\": 35.005, \"epoch\": 3.0, \"step\": 1401}, {\"eval_loss\": 0.014745385386049747, \"eval_precision\": 0.9600420609884333, \"eval_recall\": 0.9605470804839558, \"eval_f1\": 0.9602945043386799, \"eval_accuracy\": 0.9976781673789911, \"eval_runtime\": 15.1557, \"eval_samples_per_second\": 283.722, \"eval_steps_per_second\": 35.498, \"epoch\": 6.0, \"step\": 2802}, {\"eval_loss\": 0.016447067260742188, \"eval_precision\": 0.9644184811471057, \"eval_recall\": 0.95528669121515, \"eval_f1\": 0.9598308668076111, \"eval_accuracy\": 0.9975894349221373, \"eval_runtime\": 15.1965, \"eval_samples_per_second\": 282.96, \"eval_steps_per_second\": 35.403, \"epoch\": 8.0, \"step\": 3736}, {\"eval_loss\": 0.011518607847392559, \"eval_precision\": 0.9590120861797162, \"eval_recall\": 0.9600210415570752, \"eval_f1\": 0.9595162986330179, \"eval_accuracy\": 0.9977077448646091, \"eval_runtime\": 15.3321, \"eval_samples_per_second\": 280.457, \"eval_steps_per_second\": 35.09, \"epoch\": 4.0, \"step\": 1868}, {\"eval_loss\": 0.008791268803179264, \"eval_precision\": 0.9603803486529319, \"eval_recall\": 0.9563387690689111, \"eval_f1\": 0.9583552978386928, \"eval_accuracy\": 0.9976190124077552, \"eval_runtime\": 15.3224, \"eval_samples_per_second\": 280.635, \"eval_steps_per_second\": 35.112, \"epoch\": 2.0, \"step\": 934}, {\"eval_loss\": 0.009331299923360348, \"eval_precision\": 0.9645969498910676, \"eval_recall\": 0.9316149395055234, \"eval_f1\": 0.9478191062349478, \"eval_accuracy\": 0.9969830964669694, \"eval_runtime\": 15.7924, \"eval_samples_per_second\": 272.283, \"eval_steps_per_second\": 34.067, \"epoch\": 1.0, \"step\": 467}]}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons[0].read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyover(file_l:list[Path], dest_folder:str):\n",
    "    dest_folder = Path(\"history\", dest_folder)\n",
    "    dest_folder.mkdir(exist_ok=True, parents=True)\n",
    "    for f in file_l:\n",
    "        shutil.copy(f, dest_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03111215_ner2_nb-bert-large_04_101.json Seems not to have completed training\n",
      "03111215_ner2_nb-bert_base_05_101.json Seems not to have completed training\n",
      "03111215_ner2_nb-bert_base_02_101.json Seems not to have completed training\n",
      "03111215_ner2_norbert3-large_03_101.json Seems not to have completed training\n",
      "Shape: (96, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>config-file</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>eval_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [timestamp, config-file, model_name_or_path, dataset_name, output_dir, eval_f1]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "completed_paths, records = [], []\n",
    "root_keys = [\"timestamp\",  \"task\",  \"machinery\",  \"best_epoch\" ]\n",
    "args_keys = [ 'model_name_or_path', 'task_name', 'dataset_name', 'output_dir', 'seed' , 'per_device_train_batch_size',  'learning_rate' , 'num_train_epochs']\n",
    "epoch_keys = ['eval_loss', 'eval_precision', 'eval_recall', 'eval_f1', 'eval_accuracy','epoch', 'step' ]\n",
    "for j in jsons:\n",
    "    jdata = json.loads(j.read_text())\n",
    "    try:\n",
    "        for epoch_data in jdata[\"train_epochs_val\"]:\n",
    "            record = {k:v for k,v in jdata.items() if k in root_keys}\n",
    "            record[\"config-file\"] = j.name\n",
    "            record.update({k:v for k,v in jdata[\"args_dict\"].items() if k in args_keys})\n",
    "            record.update({k:v for k,v in epoch_data.items() if k in epoch_keys})\n",
    "            records.append(record)\n",
    "            completed_paths.append(j)\n",
    "    except:\n",
    "        print(j.name, \"Seems not to have completed training\")\n",
    "df = pd.DataFrame.from_records(records)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "xc_path = Path(\"excels\", name_filter+\"_full-report.xlsx\" )\n",
    "\n",
    "df.to_excel(xc_path, index=False)\n",
    "copyover(completed_paths, name_filter+\"_\"+configs_path.stem)\n",
    "df[df[\"model_name_or_path\"].isin([\"ltg/norbert3-base\"])].sort_values(\"eval_f1\", ascending=False)[[\"timestamp\",\"config-file\" ,\"model_name_or_path\" , \"dataset_name\",\"output_dir\",\"eval_f1\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report hyperparameters\n",
    "cols = [\"timestamp\",   \"machinery\", 'model_name_or_path', 'task_name', 'dataset_name', 'seed' , 'per_device_train_batch_size',  'learning_rate' , 'num_train_epochs']\n",
    "records = []\n",
    "for col in cols:\n",
    "    record = {col: df[col].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.at[1080,\"output_dir\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df[df[\"output_dir\"].isin(['/cluster/work/projects/ec30/egilron/tsa-hf/01191518_tsa-bin_NorBERT_3_base'])].sort_values(\"eval_f1\", ascending=False)[[\"timestamp\",\"config-file\" ,\"model_name_or_path\" , \"dataset_name\",\"output_dir\",\"eval_f1\"]].head(7).iterrows():\n",
    "    print(row.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"timestamp\",   \"machinery\", 'model_name_or_path','dataset_name', 'seed' , 'per_device_train_batch_size',  'learning_rate' , 'num_train_epochs']\n",
    "records = {}\n",
    "longest = 0\n",
    "for col in cols:\n",
    "    records[col]= df[col].unique()\n",
    "    longest = max(longest, len(records[col]))\n",
    "df_vars = pd.DataFrame(columns=cols)\n",
    "for i in range(longest):\n",
    "    for col in cols:\n",
    "        try:\n",
    "            df_vars.at[i, col] =records[col][i]\n",
    "            if col==\"learning_rate\":\n",
    "                df_vars.at[i, col] =f\"{records[col][i]}\"\n",
    "\n",
    "        except:\n",
    "            df_vars.at[i, col] =\"\"\n",
    "df_vars\n",
    "xc_path = Path(\"excels\", name_filter+\"_search-space.xlsx\" )\n",
    "df_vars.to_excel(xc_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machinery</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>task</th>\n",
       "      <th>config-file</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>seed</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>saga</td>\n",
       "      <td>03111215</td>\n",
       "      <td>ner2</td>\n",
       "      <td>03111215_ner2_nb-bert_base_08_101.json</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>NbAiLab/nb-bert-base</td>\n",
       "      <td>101</td>\n",
       "      <td>64</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>0.964323</td>\n",
       "      <td>0.966860</td>\n",
       "      <td>0.965590</td>\n",
       "      <td>0.997974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saga</td>\n",
       "      <td>03111215</td>\n",
       "      <td>ner2</td>\n",
       "      <td>03111215_ner2_norbert3-large_06_101.json</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>ltg/norbert3-large</td>\n",
       "      <td>101</td>\n",
       "      <td>64</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>0.954498</td>\n",
       "      <td>0.971068</td>\n",
       "      <td>0.962712</td>\n",
       "      <td>0.997737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>saga</td>\n",
       "      <td>03111215</td>\n",
       "      <td>ner2</td>\n",
       "      <td>03111215_ner2_norbert3-large_00_101.json</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>ltg/norbert3-large</td>\n",
       "      <td>101</td>\n",
       "      <td>32</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.015272</td>\n",
       "      <td>0.957292</td>\n",
       "      <td>0.966860</td>\n",
       "      <td>0.962052</td>\n",
       "      <td>0.997737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>saga</td>\n",
       "      <td>03111215</td>\n",
       "      <td>ner2</td>\n",
       "      <td>03111215_ner2_norbert3-large_09_101.json</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>ltg/norbert3-large</td>\n",
       "      <td>101</td>\n",
       "      <td>64</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>0.015519</td>\n",
       "      <td>0.960867</td>\n",
       "      <td>0.955813</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.997678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>saga</td>\n",
       "      <td>03111215</td>\n",
       "      <td>ner2</td>\n",
       "      <td>03111215_ner2_nb-bert_base_11_101.json</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>NbAiLab/nb-bert-base</td>\n",
       "      <td>101</td>\n",
       "      <td>64</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.954997</td>\n",
       "      <td>0.960021</td>\n",
       "      <td>0.957503</td>\n",
       "      <td>0.997427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machinery timestamp  task                               config-file  \\\n",
       "84      saga  03111215  ner2    03111215_ner2_nb-bert_base_08_101.json   \n",
       "0       saga  03111215  ner2  03111215_ner2_norbert3-large_06_101.json   \n",
       "48      saga  03111215  ner2  03111215_ner2_norbert3-large_00_101.json   \n",
       "36      saga  03111215  ner2  03111215_ner2_norbert3-large_09_101.json   \n",
       "72      saga  03111215  ner2    03111215_ner2_nb-bert_base_11_101.json   \n",
       "\n",
       "    num_train_epochs  best_epoch    model_name_or_path  seed  \\\n",
       "84                12          10  NbAiLab/nb-bert-base   101   \n",
       "0                 12           9    ltg/norbert3-large   101   \n",
       "48                12           5    ltg/norbert3-large   101   \n",
       "36                12           7    ltg/norbert3-large   101   \n",
       "72                12          11  NbAiLab/nb-bert-base   101   \n",
       "\n",
       "    per_device_train_batch_size learning_rate  eval_loss  eval_precision  \\\n",
       "84                           64         1e-05   0.012571        0.964323   \n",
       "0                            64         1e-05   0.015711        0.954498   \n",
       "48                           32         1e-05   0.015272        0.957292   \n",
       "36                           64         5e-05   0.015519        0.960867   \n",
       "72                           64         5e-05   0.018261        0.954997   \n",
       "\n",
       "    eval_recall   eval_f1  eval_accuracy  \n",
       "84     0.966860  0.965590       0.997974  \n",
       "0      0.971068  0.962712       0.997737  \n",
       "48     0.966860  0.962052       0.997737  \n",
       "36     0.955813  0.958333       0.997678  \n",
       "72     0.960021  0.957503       0.997427  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best epochs only\n",
    "df_bests = df.loc[ df[\"epoch\"] ==df[\"best_epoch\"]].copy()\n",
    "df_bests[\"learning_rate\"] = df_bests[\"learning_rate\"].apply(lambda x: f\"{x:.0e}\")\n",
    "report = df_bests[['machinery','timestamp', 'task', \"config-file\", 'num_train_epochs', 'best_epoch', \n",
    "       'model_name_or_path', 'seed',\n",
    "       'per_device_train_batch_size',  \n",
    "      'learning_rate', 'eval_loss', 'eval_precision',\n",
    "       'eval_recall', 'eval_f1', 'eval_accuracy',  ]].sort_values(\"eval_f1\", ascending=False)\n",
    "xc_path = Path(\"excels\", name_filter+\"_best-report.xlsx\" )\n",
    "report.to_excel(xc_path, index=False)\n",
    "report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ja.json'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list({1:11}.values())[0]\n",
    "from pathlib import Path\n",
    "Path(\"ja.json\").name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
