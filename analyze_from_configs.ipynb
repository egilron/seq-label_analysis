{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get config jsons from fine-tuning experiments and analyze\n",
    "\n",
    "## Ny kj√∏ring i 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys, io, shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03081014: elsa-intensity 30\n",
      "03091023: elsa-intensity 60\n"
     ]
    }
   ],
   "source": [
    "# Get timestamps and tasks\n",
    "configs_path = Path(\"/home/egil/gits_wsl/seq-label-github/configs/saga\")\n",
    "all_jsons = [f for f in configs_path.iterdir() if f.name.endswith(\"json\")]\n",
    "all_jsons = [(f.stem.split(\"_\")[0], f.stem.split(\"_\")[1], f) for f in all_jsons]\n",
    "timestamps = sorted(list(set([j[0] for j in all_jsons])))\n",
    "for t in timestamps:\n",
    "    tasks = set([j[1] for j in all_jsons if j[0]==t])\n",
    "    for task in tasks:\n",
    "        print(f\"{t}: {task}\", len([j for j in all_jsons if j[0]==t and j[1]==task]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "name_filter = [\"0115\", \"0117\"]\n",
    "name_filter = [\"01191518_tsa-bin_NB-BERT_large_07-b\"]\n",
    "name_filter = [\"03091023\"] # \"01170944\" # \n",
    "jsons = [f[2] for f in all_jsons if any([f[0] in n for n in name_filter])]\n",
    "jsons = [f[2] for f in all_jsons if name_filter[0] in f[2].name]\n",
    "\n",
    "name_filter = \"_\".join(name_filter)\n",
    "len(jsons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"timestamp\": \"03091023\", \"num_seeds\": 5, \"task\": \"elsa-intensity\", \"model_shortname\": \"norbert3-large\", \"machinery\": \"saga\", \"local_dataset\": true, \"args_dict\": {\"model_name_or_path\": \"ltg/norbert3-large\", \"dataset_name\": \"data/elsa-dataset_seqlabel\", \"seed\": 505, \"per_device_train_batch_size\": 32, \"task_name\": \"03091023_elsa-intensity_norbert3-large\", \"output_dir\": \"/cluster/work/users/egilron/finetunes/03091023_elsa-intensity_norbert3-large\", \"overwrite_cache\": true, \"overwrite_output_dir\": true, \"do_train\": true, \"num_train_epochs\": 12, \"do_eval\": true, \"return_entity_level_metrics\": false, \"use_auth_token\": false, \"logging_strategy\": \"epoch\", \"save_strategy\": \"epoch\", \"evaluation_strategy\": \"epoch\", \"save_total_limit\": 1, \"load_best_model_at_end\": true, \"label_column_name\": \"elsa_labels\", \"disable_tqdm\": true, \"report_to\": null, \"do_predict\": true, \"text_column_name\": \"tokens\", \"learning_rate\": 1e-05, \"trust_remote_code\": true}, \"best_epoch\": 1, \"train_epochs_val\": [{\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 6.3997, \"eval_samples_per_second\": 236.419, \"eval_steps_per_second\": 29.689, \"epoch\": 1.0, \"step\": 268}, {\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 5.8816, \"eval_samples_per_second\": 257.242, \"eval_steps_per_second\": 32.304, \"epoch\": 2.0, \"step\": 536}, {\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 5.8996, \"eval_samples_per_second\": 256.46, \"eval_steps_per_second\": 32.206, \"epoch\": 3.0, \"step\": 804}, {\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 5.8995, \"eval_samples_per_second\": 256.463, \"eval_steps_per_second\": 32.206, \"epoch\": 4.0, \"step\": 1072}, {\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 5.8925, \"eval_samples_per_second\": 256.768, \"eval_steps_per_second\": 32.245, \"epoch\": 5.0, \"step\": 1340}, {\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 5.8944, \"eval_samples_per_second\": 256.682, \"eval_steps_per_second\": 32.234, \"epoch\": 6.0, \"step\": 1608}, {\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 5.8641, \"eval_samples_per_second\": 258.011, \"eval_steps_per_second\": 32.401, \"epoch\": 7.0, \"step\": 1876}, {\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 5.8592, \"eval_samples_per_second\": 258.226, \"eval_steps_per_second\": 32.428, \"epoch\": 8.0, \"step\": 2144}, {\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 5.8693, \"eval_samples_per_second\": 257.783, \"eval_steps_per_second\": 32.372, \"epoch\": 9.0, \"step\": 2412}, {\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 6.1706, \"eval_samples_per_second\": 245.194, \"eval_steps_per_second\": 30.791, \"epoch\": 10.0, \"step\": 2680}, {\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 5.9036, \"eval_samples_per_second\": 256.285, \"eval_steps_per_second\": 32.184, \"epoch\": 11.0, \"step\": 2948}, {\"eval_loss\": NaN, \"eval_precision\": 0.0, \"eval_recall\": 0.0, \"eval_f1\": 0.0, \"eval_accuracy\": 0.9625200297025833, \"eval_runtime\": 5.9083, \"eval_samples_per_second\": 256.078, \"eval_steps_per_second\": 32.158, \"epoch\": 12.0, \"step\": 3216}]}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons[0].read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyover(file_l:list[Path], dest_folder:str):\n",
    "    dest_folder = Path(\"history\", dest_folder)\n",
    "    dest_folder.mkdir(exist_ok=True, parents=True)\n",
    "    for f in file_l:\n",
    "        shutil.copy(f, dest_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (720, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>config-file</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>eval_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [timestamp, config-file, model_name_or_path, dataset_name, output_dir, eval_f1]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "completed_paths, records = [], []\n",
    "root_keys = [\"timestamp\",  \"task\",  \"machinery\",  \"best_epoch\" ]\n",
    "args_keys = [ 'model_name_or_path', 'task_name', 'dataset_name', 'output_dir', 'seed' , 'per_device_train_batch_size',  'learning_rate' , 'num_train_epochs']\n",
    "epoch_keys = ['eval_loss', 'eval_precision', 'eval_recall', 'eval_f1', 'eval_accuracy','epoch', 'step' ]\n",
    "for j in jsons:\n",
    "    jdata = json.loads(j.read_text())\n",
    "    try:\n",
    "        for epoch_data in jdata[\"train_epochs_val\"]:\n",
    "            record = {k:v for k,v in jdata.items() if k in root_keys}\n",
    "            record[\"config-file\"] = j.name\n",
    "            record.update({k:v for k,v in jdata[\"args_dict\"].items() if k in args_keys})\n",
    "            record.update({k:v for k,v in epoch_data.items() if k in epoch_keys})\n",
    "            records.append(record)\n",
    "            completed_paths.append(j)\n",
    "    except:\n",
    "        print(j.name, \"Seems not to have completed training\")\n",
    "df = pd.DataFrame.from_records(records)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "xc_path = Path(\"excels\", name_filter+\"_full-report.xlsx\" )\n",
    "\n",
    "df.to_excel(xc_path, index=False)\n",
    "copyover(completed_paths, name_filter+\"_\"+configs_path.stem)\n",
    "df[df[\"model_name_or_path\"].isin([\"ltg/norbert3-base\"])].sort_values(\"eval_f1\", ascending=False)[[\"timestamp\",\"config-file\" ,\"model_name_or_path\" , \"dataset_name\",\"output_dir\",\"eval_f1\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report hyperparameters\n",
    "cols = [\"timestamp\",   \"machinery\", 'model_name_or_path', 'task_name', 'dataset_name', 'seed' , 'per_device_train_batch_size',  'learning_rate' , 'num_train_epochs']\n",
    "records = []\n",
    "for col in cols:\n",
    "    record = {col: df[col].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.at[1080,\"output_dir\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df[df[\"output_dir\"].isin(['/cluster/work/projects/ec30/egilron/tsa-hf/01191518_tsa-bin_NorBERT_3_base'])].sort_values(\"eval_f1\", ascending=False)[[\"timestamp\",\"config-file\" ,\"model_name_or_path\" , \"dataset_name\",\"output_dir\",\"eval_f1\"]].head(7).iterrows():\n",
    "    print(row.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"timestamp\",   \"machinery\", 'model_name_or_path','dataset_name', 'seed' , 'per_device_train_batch_size',  'learning_rate' , 'num_train_epochs']\n",
    "records = {}\n",
    "longest = 0\n",
    "for col in cols:\n",
    "    records[col]= df[col].unique()\n",
    "    longest = max(longest, len(records[col]))\n",
    "df_vars = pd.DataFrame(columns=cols)\n",
    "for i in range(longest):\n",
    "    for col in cols:\n",
    "        try:\n",
    "            df_vars.at[i, col] =records[col][i]\n",
    "            if col==\"learning_rate\":\n",
    "                df_vars.at[i, col] =f\"{records[col][i]}\"\n",
    "\n",
    "        except:\n",
    "            df_vars.at[i, col] =\"\"\n",
    "df_vars\n",
    "xc_path = Path(\"excels\", name_filter+\"_search-space.xlsx\" )\n",
    "df_vars.to_excel(xc_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>task</th>\n",
       "      <th>machinery</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>03091023</td>\n",
       "      <td>elsa-intensity</td>\n",
       "      <td>saga</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>NbAiLab/nb-bert-large</td>\n",
       "      <td>32</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.039726</td>\n",
       "      <td>0.729299</td>\n",
       "      <td>0.737520</td>\n",
       "      <td>0.733387</td>\n",
       "      <td>0.989174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>03091023</td>\n",
       "      <td>elsa-intensity</td>\n",
       "      <td>saga</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>NbAiLab/nb-bert-large</td>\n",
       "      <td>32</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>0.048178</td>\n",
       "      <td>0.719380</td>\n",
       "      <td>0.747182</td>\n",
       "      <td>0.733017</td>\n",
       "      <td>0.989018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>03091023</td>\n",
       "      <td>elsa-intensity</td>\n",
       "      <td>saga</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>NbAiLab/nb-bert-large</td>\n",
       "      <td>64</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.057877</td>\n",
       "      <td>0.729600</td>\n",
       "      <td>0.734300</td>\n",
       "      <td>0.731942</td>\n",
       "      <td>0.988940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>03091023</td>\n",
       "      <td>elsa-intensity</td>\n",
       "      <td>saga</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>NbAiLab/nb-bert-large</td>\n",
       "      <td>32</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.048783</td>\n",
       "      <td>0.716952</td>\n",
       "      <td>0.742351</td>\n",
       "      <td>0.729430</td>\n",
       "      <td>0.989057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>03091023</td>\n",
       "      <td>elsa-intensity</td>\n",
       "      <td>saga</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>NbAiLab/nb-bert-large</td>\n",
       "      <td>64</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>0.050241</td>\n",
       "      <td>0.726400</td>\n",
       "      <td>0.731079</td>\n",
       "      <td>0.728732</td>\n",
       "      <td>0.989174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp            task machinery  num_train_epochs  best_epoch  \\\n",
       "456  03091023  elsa-intensity      saga                12           3   \n",
       "144  03091023  elsa-intensity      saga                12           3   \n",
       "576  03091023  elsa-intensity      saga                12          10   \n",
       "552  03091023  elsa-intensity      saga                12           6   \n",
       "480  03091023  elsa-intensity      saga                12           3   \n",
       "\n",
       "        model_name_or_path  per_device_train_batch_size learning_rate  \\\n",
       "456  NbAiLab/nb-bert-large                           32         1e-05   \n",
       "144  NbAiLab/nb-bert-large                           32         5e-05   \n",
       "576  NbAiLab/nb-bert-large                           64         1e-05   \n",
       "552  NbAiLab/nb-bert-large                           32         1e-05   \n",
       "480  NbAiLab/nb-bert-large                           64         5e-05   \n",
       "\n",
       "     eval_loss  eval_precision  eval_recall   eval_f1  eval_accuracy  \n",
       "456   0.039726        0.729299     0.737520  0.733387       0.989174  \n",
       "144   0.048178        0.719380     0.747182  0.733017       0.989018  \n",
       "576   0.057877        0.729600     0.734300  0.731942       0.988940  \n",
       "552   0.048783        0.716952     0.742351  0.729430       0.989057  \n",
       "480   0.050241        0.726400     0.731079  0.728732       0.989174  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best epochs only\n",
    "df_bests = df.loc[ df[\"epoch\"] ==df[\"best_epoch\"]].copy()\n",
    "df_bests[\"learning_rate\"] = df_bests[\"learning_rate\"].apply(lambda x: f\"{x:.0e}\")\n",
    "report = df_bests[['timestamp', 'task', 'machinery', 'num_train_epochs', 'best_epoch', \n",
    "       'model_name_or_path',\n",
    "       'per_device_train_batch_size',  \n",
    "      'learning_rate', 'eval_loss', 'eval_precision',\n",
    "       'eval_recall', 'eval_f1', 'eval_accuracy',  ]].sort_values(\"eval_f1\", ascending=False)\n",
    "xc_path = Path(\"excels\", name_filter+\"_best-report.xlsx\" )\n",
    "report.to_excel(xc_path, index=False)\n",
    "report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ja.json'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list({1:11}.values())[0]\n",
    "from pathlib import Path\n",
    "Path(\"ja.json\").name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
